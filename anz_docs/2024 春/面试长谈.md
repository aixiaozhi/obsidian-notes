### gshare
用推测的更新，指令包大小128bit
原来bimodal的深度为11bit，也就是 256bytes，bimodal和gshare对于coremark性能接近
然后14bit深度(2k bytes)的bimodal准确率只是从87%提高到了88%，但是12bit的gshare就要好了，14bit深度的gshare对于bimodal准确率吧为92%，coremark评分从2.95到了3.1
tips:推测更新，前端放一个history序列，后端放一个history序列，预测错了就更新
同一个指令包如果判断有多条分支指令，第二条哈希history的时候末尾补0（默认第一条不跳），因为跳了大概率也跳走了没有用

**分支预测：分支预测器本质上是在学习特征（pattern）和分支结果的mapping. 通常的pattern包括分支指令的PC和分支的历史信息**
**gshare为什么有时候会不如bimodal:1.事实上分支预测方法很大程度上依赖程序的行为，Gshare不可能对于任何一种程序都是最优良的。
2.在小面积上相近是因为这个程序小的全局历史的哈希并不能很好的解决aliasing问题，仍在存在很多低PC位和全局历史相同的pattern。也可以说是因为同样都”面积小“的情况下，很多分支的情况都”挤在一起“，只有大到一定程度的pht才能反映出区分的优势。**

### TAGE的优点
1. Taged,目前分支预测的索引一般为PC或者PC和global history的xor，出于存储效率考虑，只有一部分会用于索引，会有aliasing。这个时候如果把多余的PC存起来做tag，就能更好地比对出哪些是真match，哪些是aliasing，有助于选取到真正对应的entry。  
  
2. GE（Geometrical）主流观点认为一般global history match的长度越多，预测就越准确。所以TAGE选取了几何增长的history长度，如32，64，128，256。原则上，每次优先选取最长的match做预测。

### cache相关
cache最低位是字节，因为i-cache最小指令是2bytes，所以最低一位不用管，但是data cache最低一位是字节，所以用管。
假设一个包含4096个cache line的cache，cache line大小为4 words，地址长度64位，按直接映射，两路组相联，四路和全相联的结构，分别计算组数和tag总容量
**解：cache line大小是16bytes，也就是 block offset ：4； index直接映射：12位，2路11位，4路10位，全相连0位
直接映射：58 x 4096。2路组相联：59 x 2 x 2048。4路:58 x4x1024。全60 x 4096

### 分支指令
b-type：地址能直接从指令中得到，但是得比较寄存器
j-type：jal为立即跳转，指令地址可得到，jalr为间接跳转，指令地址需要访问寄存器
按照分支指令是否需要满足某条件后才会发生分支跳转，将指令执行方式分为条件执行和非条件执行。
按照指令寻址模式（直接寻址和间接寻址）的不同，分为直接寻址分支和间接寻址分支
只有b-type的方向和jalr的地址会留到后端解决，分支预测错误的恢复方式是checkpoint
**checkpoint**:跟在每条分支后的指令都有一个编号，当检测分支错误的时候，把相应的分支编号的

### 内存一致性模型：在多核共享存储空间的场景下，对单核（hart）访存顺序的限制；或者说，单核访存需要遵守的规则
Sequential内存一致性模型：对于顺序和乱序的CPU都严格按照程序要求的顺序执行对内存的存取（load和store）操作。
然后有relaxed内存一致性模型： 放松W->R顺序：我们就得到了TSO(total store ordering)模型，它允许CPU先执行读操作然后在执行写操作而不严格按照代码的指示顺序来进行。放松W-W顺序等。

### 分频器
**任意偶数** cnt== num /2 - 1;比如4分频，每两下反转一下；用parameter写 cnt；
**任意奇数** cnt== (num-1)/2 一个上升沿，一个下降沿；例如7分频，一个4，3；一个3，4；
**异步复位同步释放**：如果rst_n和clk上升沿同时到来，rst_n提前一点，直接置0，不会有毛刺，因为上升沿到来之后rst_n仍然为0，但是，当rstn释放的时候（从0变1）时，如果rstn释放边沿和clk释放边沿很接近，那么就会出现亚稳态。不能靠rst_n的跳高来跳高
![[Pasted image 20240326192725.png|400]]

**序列检测** 注意状态机转换 或者简单的**移位寄存器**就可以
**流水线关键** assign ready_o=!vld || ready_i **这一级肚子里没货或者下一级准备好了**

**解耦前端设计的好处**：允许BPU跑的比ICACHE快很多，不至于ICACHE阻塞BPU也阻塞，2.ICACHE的预取普遍采用fetch directed instruction prefetch，即用分支预测指导ICACHE预取，cache预取器能去FTQ找到未来的指令流

**FTQ相关**：FTQ用8个大寄存器堆先存放BPU s1,s2级的所有信息，ROB与FTQ交互大部分是因为要提交，清掉FTQ里的SRAM存储的分支预测的meta信息，不用再返回训练

**LSU几级流水**：store 3级流水，load也是3级。**违例恢复.** 触发 load-load 违例的 load 指令会被标记为需要从取指重新执行. 重定向请求会在这些指令到达 ROB 队尾时发出。

**VIPT和PIPT的区别，怎么弄

**怎么弄4选1**

**为什么采用解耦的设计

### 你有什么要问我的?
公司的晋升和培养机制是什么？/晋升渠道和条件
暑期实习会对秋招有正面/负面的影响吗
想问问我所应聘的部门的规模和架构？
接下来下半年部门的工作重心是？

### 优点
比较有挑战心，坚韧，自省

### 缺点
比较冲动，缺乏领导力










